{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ef533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import gc\n",
    "import time\n",
    "# import spaces         # only for web demo\n",
    "\n",
    "from pi3.utils.geometry import se3_inverse, homogenize_points, depth_edge\n",
    "from pi3.models.pi3 import Pi3\n",
    "from pi3.utils.basic import load_images_as_tensor\n",
    "# import torch._dynamo\n",
    "# torch._dynamo.config.accumulated_cache_size_limit = 10240\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e38b075",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = Pi3.from_pretrained(\"yyfz233/Pi3\").to(device).eval()\n",
    "model = torch.compile(model)\n",
    "\n",
    "target_dir = \"/root/repos/Pi3/input_images_20250814_090447_171967\"\n",
    "imgs = load_images_as_tensor(os.path.join(target_dir, \"images\"), interval=1, PIXEL_LIMIT=255000).to(device)\n",
    "\n",
    "print(\"Running model inference...\")\n",
    "dtype = torch.bfloat16\n",
    "with torch.no_grad():\n",
    "    with torch.amp.autocast('cuda', dtype=dtype):\n",
    "        # Run inference 10 times and compute average time\n",
    "        times = []\n",
    "        num_run = 10\n",
    "        for _ in range(num_run):\n",
    "            torch.cuda.synchronize()\n",
    "            t0 = time.time()\n",
    "            predictions = model(imgs[None].to(\"cuda:0\"))  # Ensure input is on the first device of tensor parallel\n",
    "            if _ == 0:\n",
    "                print(f\"imgs[None] shape: {imgs[None].shape}\")\n",
    "            torch.cuda.synchronize()\n",
    "            t1 = time.time()\n",
    "            times.append(t1 - t0)\n",
    "        # Remove top 5 time diffs (slowest runs)\n",
    "        times_sorted = sorted(times)\n",
    "        if len(times_sorted) > 5:\n",
    "            times_filtered = times_sorted[:-5]\n",
    "        else:\n",
    "            times_filtered = times_sorted\n",
    "        avg_time = sum(times_filtered) / len(times_filtered)\n",
    "        print(f\"Average inference time over {len(times_filtered)} runs (top 5 removed): {avg_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d70a5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(img_tensors):\n",
    "    with torch.amp.autocast('cuda', dtype=dtype):\n",
    "        for _ in range(num_run):\n",
    "            torch.cuda.synchronize()\n",
    "            t0 = time.time()\n",
    "            predictions = model(imgs[None].to(\"cuda:0\"))  # Ensure input is on the first device of tensor parallel\n",
    "            if _ == 0:\n",
    "                print(f\"imgs[None] shape: {imgs[None].shape}\")\n",
    "            torch.cuda.synchronize()\n",
    "            t1 = time.time()\n",
    "            times.append(t1 - t0)\n",
    "        # Remove top 5 time diffs (slowest runs)\n",
    "        times_sorted = sorted(times)\n",
    "        if len(times_sorted) > 5:\n",
    "            times_filtered = times_sorted[:-5]\n",
    "        else:\n",
    "            times_filtered = times_sorted\n",
    "        avg_time = sum(times_filtered) / len(times_filtered)\n",
    "        print(f\"Average inference time over {len(times_filtered)} runs (top 5 removed): {avg_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2270e8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning, cannot find cuda-compiled version of RoPE2D, using a slow pytorch version instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from directory: /root/repos/Pi3/input_images_20250814_090447_171967/images\n",
      "Found 2 images/frames. Processing...\n",
      "All images will be resized to a uniform size: (672, 378)\n",
      "Loading images from directory: /root/repos/Pi3/input_images_20250814_090447_171967/images\n",
      "Found 2 images/frames. Processing...\n",
      "All images will be resized to a uniform size: (672, 378)\n",
      "Loading images from directory: /root/repos/Pi3/input_images_20250814_090447_171967/images\n",
      "Found 2 images/frames. Processing...\n",
      "All images will be resized to a uniform size: (672, 378)\n",
      "All finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/conda/envs/pi3/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/envs/pi3/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'worker' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/conda/envs/pi3/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/envs/pi3/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'worker' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/conda/envs/pi3/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/envs/pi3/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'worker' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 只能在 test.py 中运行，在jupyter中会报错\n",
    "\n",
    "\n",
    "import multiprocessing\n",
    "import time\n",
    "import random\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from itertools import count\n",
    "from pi3.utils.geometry import se3_inverse, homogenize_points, depth_edge\n",
    "from pi3.models.pi3 import Pi3\n",
    "from pi3.utils.basic import load_images_as_tensor\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "# Konfiguration\n",
    "NUM_GPUS = 3\n",
    "PROCESSING_TIME_MIN_MS = 50\n",
    "PROCESSING_TIME_MAX_MS = 200\n",
    "CLIENT_REQUEST_INTERVAL_MS = 30\n",
    "TOTAL_REQUESTS = 20000\n",
    "\n",
    "\n",
    "device_list = [\"cuda:0\", \"cuda:1\", \"cuda:2\"]\n",
    "# model_list = [\n",
    "#     torch.compile(Pi3.from_pretrained(\"yyfz233/Pi3\").to(device_list[i]).eval())\n",
    "#     for i in range(NUM_GPUS)\n",
    "# ]\n",
    "# change the above code to parallel load parameters\n",
    "\n",
    "import torch, torch.multiprocessing as mp, os\n",
    "\n",
    "model_dict = {}\n",
    "\n",
    "def worker(rank, data):\n",
    "    torch.cuda.set_device(rank)\n",
    "    if model_dict.get(rank) is None:\n",
    "        sys.stdout.write(f\"Loading model on gpu-{rank}\\n\")\n",
    "        sys.stdout.flush()\n",
    "        model = torch.compile(Pi3.from_pretrained(\"yyfz233/Pi3\").to(device_list[rank]).eval())\n",
    "        model_dict[rank] = model\n",
    "    model = model_dict[rank]\n",
    "    data = data.to(device_list[rank])\n",
    "    dtype = torch.bfloat16\n",
    "    with torch.no_grad():\n",
    "        with torch.amp.autocast('cuda', dtype=dtype):\n",
    "            # output = model(data[None])\n",
    "            times = []\n",
    "            num_run = 10\n",
    "            for _ in range(num_run):\n",
    "                torch.cuda.synchronize()\n",
    "                t0 = time.time()\n",
    "                predictions = model(data[None])  # Add batch dimension\n",
    "                torch.cuda.synchronize()\n",
    "                t1 = time.time()\n",
    "                times.append(t1 - t0)\n",
    "            # Remove top 5 time diffs (slowest runs)\n",
    "            times_sorted = sorted(times)\n",
    "            if len(times_sorted) > 5:\n",
    "                times_filtered = times_sorted[:-5]\n",
    "            else:\n",
    "                times_filtered = times_sorted\n",
    "            avg_time = sum(times_filtered) / len(times_filtered)\n",
    "            sys.stdout.write(f\"GPU-{rank} Average inference time over {len(times_filtered)} runs (top 5 removed): {avg_time:.4f} seconds\\n\")\n",
    "            sys.stdout.flush()\n",
    "        # Process output\n",
    "        sys.stdout.write(f\"Processed data on gpu-{rank}\\n\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mp.set_start_method(\"spawn\")\n",
    "    torch._dynamo.config.capture_scalar_outputs = True\n",
    "    torch.set_float32_matmul_precision('high')\n",
    "    world_size = torch.cuda.device_count()\n",
    "    target_dir = \"/root/repos/Pi3/input_images_20250814_090447_171967\"\n",
    "    data_list = []\n",
    "    for i in range(NUM_GPUS):\n",
    "        imgs = load_images_as_tensor(os.path.join(target_dir, \"images\"), interval=1, PIXEL_LIMIT=255000).to(device_list[i])\n",
    "        data_list.append(imgs)\n",
    "\n",
    "    procs = []\n",
    "    for rank in range(world_size):\n",
    "        p = mp.Process(target=worker, args=(rank, data_list[rank]))\n",
    "        p.start()\n",
    "        procs.append(p)\n",
    "\n",
    "    for p in procs:\n",
    "        p.join()\n",
    "    print(\"All finished.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb8c2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model_on_gpu(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a770f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_ms():\n",
    "    \"\"\"Gibt die aktuelle Zeit in Millisekunden zurück.\"\"\"\n",
    "    return int(time.time() * 1000)\n",
    "\n",
    "def gpu_worker(task_id, gpu_id, imgs):\n",
    "    \"\"\"\n",
    "    Simuliert die Verarbeitung von Bildern auf einer GPU.\n",
    "    \"\"\"\n",
    "    start_processing_time = get_time_ms()\n",
    "    processing_duration = random.randint(PROCESSING_TIME_MIN_MS, PROCESSING_TIME_MAX_MS)\n",
    "    time.sleep(processing_duration / 1000.0)\n",
    "    end_processing_time = get_time_ms()\n",
    "    \n",
    "    result = {\n",
    "        \"task_id\": task_id,\n",
    "        \"gpu_id\" : gpu_id,\n",
    "        \"status\": \"processed\",\n",
    "        \"start_processing_time\": start_processing_time,\n",
    "        \"end_processing_time\": end_processing_time,\n",
    "        \"processing_duration_ms\": end_processing_time - start_processing_time,\n",
    "    }\n",
    "    return result\n",
    "\n",
    "def server_process(request_queue, result_queue):\n",
    "    gpu_pool = ProcessPoolExecutor(max_workers=NUM_GPUS)\n",
    "    gpu_iterator = count()\n",
    "\n",
    "    futures = {}\n",
    "\n",
    "    while True:\n",
    "        # Auf neue Anfragen warten\n",
    "        if not request_queue.empty():\n",
    "            task = request_queue.get()\n",
    "            if task == \"STOP\":\n",
    "                break\n",
    "\n",
    "            task_id, image_data, client_send_time = task\n",
    "            server_receive_time = get_time_ms()\n",
    "            \n",
    "            gpu_id = next(gpu_iterator) % NUM_GPUS\n",
    "            # Aufgabe an einen GPU-Worker senden\n",
    "            future = gpu_pool.submit(gpu_worker, task_id, image_data)\n",
    "            futures[future] = (task_id, server_receive_time)\n",
    "\n",
    "        # Abgeschlossene Aufgaben prüfen\n",
    "        for future in list(futures):\n",
    "            if future.done():\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    task_id, server_receive_time = futures.pop(future)\n",
    "                    server_send_time = get_time_ms()\n",
    "                    result[\"server_receive_time\"] = server_receive_time\n",
    "                    result[\"server_send_time\"] = server_send_time\n",
    "                    result_queue.put(result)\n",
    "                except Exception as e:\n",
    "                    print(f\"[Server] Fehler bei der Verarbeitung von Aufgabe: {e}\")\n",
    "                    task_id, _ = futures.pop(future)\n",
    "                    # Fehler an den Client senden\n",
    "                    error_result = {\n",
    "                        \"task_id\": task_id,\n",
    "                        \"status\": \"error\",\n",
    "                        \"error_message\": str(e),\n",
    "                    }\n",
    "                    result_queue.put(error_result)\n",
    "\n",
    "\n",
    "    gpu_pool.shutdown()\n",
    "    print(\"[Server] Server wurde heruntergefahren.\")\n",
    "\n",
    "def client_process(request_queue, result_queue):\n",
    "    \"\"\"\n",
    "    Der Clientprozess, der regelmäßig Anfragen sendet.\n",
    "    \"\"\"\n",
    "    print(\"[Client] Client wird gestartet...\")\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    target_dir = \"/root/repos/Pi3/input_images_20250814_090447_171967\"\n",
    "    imgs = load_images_as_tensor(os.path.join(target_dir, \"images\"), interval=1, PIXEL_LIMIT=255000).to(device)\n",
    "\n",
    "    for i in range(TOTAL_REQUESTS):\n",
    "        task_id = f\"Task-{i+1}\"\n",
    "        # image_data = [\"image_data_1\", \"image_data_2\"]\n",
    "        \n",
    "        client_send_time = get_time_ms()\n",
    "        request_queue.put((task_id, imgs, client_send_time))\n",
    "        print(f\"[{client_send_time}ms] [Client] Anfrage {task_id} gesendet.\")\n",
    "        \n",
    "        time.sleep(CLIENT_REQUEST_INTERVAL_MS / 1000.0)\n",
    "\n",
    "    # Signal zum Beenden an den Server senden\n",
    "    request_queue.put(\"STOP\")\n",
    "    \n",
    "    # Auf Ergebnisse warten\n",
    "    completed_requests = 0\n",
    "    while completed_requests < TOTAL_REQUESTS:\n",
    "        if not result_queue.empty():\n",
    "            result = result_queue.get()\n",
    "            client_receive_time = get_time_ms()\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(f\"[{client_receive_time}ms] [Client] Ergebnis für {result['task_id']} erhalten.\")\n",
    "            \n",
    "            if result['status'] == 'processed':\n",
    "                total_duration = client_receive_time - result['server_receive_time'] + (result['server_receive_time'] - result['start_processing_time'])\n",
    "                print(f\"  - GPU-Verarbeitungsdauer: {result['processing_duration_ms']}ms\")\n",
    "                print(f\"  - Gesamtdauer:              {total_duration}ms\")\n",
    "            else:\n",
    "                print(f\"  - Fehler bei der Verarbeitung: {result['error_message']}\")\n",
    "            print(\"=\"*50 + \"\\n\")\n",
    "            \n",
    "            completed_requests += 1\n",
    "\n",
    "    print(\"[Client] Client hat alle Antworten erhalten und wird beendet.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    multiprocessing.set_start_method('spawn')\n",
    "    \n",
    "    # Warteschlangen für die Kommunikation zwischen den Prozessen erstellen\n",
    "    requests = multiprocessing.Queue()\n",
    "    results = multiprocessing.Queue()\n",
    "\n",
    "    # Server- und Client-Prozesse erstellen\n",
    "    server = multiprocessing.Process(target=server_process, args=(requests, results))\n",
    "    client = multiprocessing.Process(target=client_process, args=(requests, results))\n",
    "\n",
    "    # Prozesse starten\n",
    "    server.start()\n",
    "    client.start()\n",
    "\n",
    "    # Auf das Ende der Prozesse warten\n",
    "    client.join()\n",
    "    server.join()\n",
    "\n",
    "    print(\"Simulation abgeschlossen.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pi3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
